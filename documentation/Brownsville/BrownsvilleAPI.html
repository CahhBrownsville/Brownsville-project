<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>Brownsville.BrownsvilleAPI API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>Brownsville.BrownsvilleAPI</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import json
import os
from typing import Any, List, Tuple, Union

from branca.element import CssLink
import folium
import folium.plugins
import numpy as np
import pandas as pd
import yaml

from .data_api import Client
from .geocode import GeocodeClient


class InvalidColumnNameError(Exception):
    def __init__(self, msg: str = &#34;Invalid column name passed&#34;) -&gt; None:
        super().__init__(msg)


class Brownsville:
    def __init__(
        self, path: str = &#34;./data/brownsville/&#34;, force_load: bool = False
    ) -&gt; None:
        self.path = path

        # Create the directory where the dataset will be stored
        if not os.path.exists(self.path):
            os.mkdir(self.path)

        self.config = self.__load_config()
        self.geocode_client = GeocodeClient(self.config[&#34;geocode&#34;][&#34;app_token&#34;])

        self.__load_dataset(force_load)
        self.__translate_ids()
        self.__parse_datatypes()
        self.__set_addresses()

        self.__get_spatial_information()

        # self.__filter_no_complaints()

        self._map = self.__update_map()

    @property
    def buildings(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Returns an NumPy ndarray with the set of unique buildings in the dataset by building id.
        &#34;&#34;&#34;
        return self.data[&#34;buildingid&#34;].unique()

    @property
    def complaints(self) -&gt; pd.Series:
        &#34;&#34;&#34;
        Returns a Pandas DataFrame with building_id&#39;s and their respective
        number of complaints reported.
        &#34;&#34;&#34;

        # complaints = np.zeros(len(self.buildings))
        # for i, building_id in enumerate(self.buildings):
        #     num_of_complaints = self.complaint_number(building_id)
        #     complaints[i] = num_of_complaints

        # df = pd.DataFrame({&#34;buildingid&#34;: self.buildings, &#34;complaints&#34;: complaints})

        # return df
        return self.data[&#34;buildingid&#34;].value_counts()

    def get_date_range(self, by: str = &#34;status&#34;) -&gt; Tuple[pd.Timestamp, pd.Timestamp]:
        &#34;&#34;&#34;
        Return the date range for the complaint since the day it was marked as complete or
        since the day it was received.

        Parameters:
        -----------
        by: `str`
            Feature to get the data range by.
        &#34;&#34;&#34;
        if by not in (&#34;status&#34;, &#34;received&#34;):
            raise InvalidColumnNameError()

        by += &#34;date&#34;

        return self.data[by].min(), self.data[by].max()

    def records_by_season(self) -&gt; Tuple[List, List]:
        &#34;&#34;&#34;
        Return the number of complaints reported by season.
        &#34;&#34;&#34;
        date_counts = self.records_by_date(period=&#34;month&#34;)

        seasons = [&#34;Winter&#34;, &#34;Spring&#34;, &#34;Summer&#34;, &#34;Autumn&#34;]
        values = [
            date_counts.loc[[&#34;Jan&#34;, &#34;Feb&#34;, &#34;Mar&#34;]].sum(),
            date_counts.loc[[&#34;Apr&#34;, &#34;May&#34;, &#34;Jun&#34;]].sum(),
            date_counts.loc[[&#34;Jul&#34;, &#34;Aug&#34;, &#34;Sep&#34;]].sum(),
            date_counts.loc[[&#34;Oct&#34;, &#34;Nov&#34;, &#34;Dec&#34;]].sum(),
        ]
        print(f&#34;{seasons[0]}: {values[0]}&#34;)
        print(f&#34;{seasons[1]}: {values[1]}&#34;)
        print(f&#34;{seasons[2]}: {values[2]}&#34;)
        print(f&#34;{seasons[3]}: {values[3]}&#34;)

        return seasons, values

    def records_by_date(
        self, period: str = &#34;month&#34;, step: int = 1, num_years: int = 0
    ) -&gt; set:
        &#34;&#34;&#34;
        Return the number of complaints reported on a monthly or yearly basis.

        Parameters:
        -----------
        period: `str`
            Type of time period to return the number of complaint reported.
        step: `int`
            Number of year intervals to separate the data. *Only works if period is `year`*
        num_years `int`
            Number of past years to query the data. *Only works if period is `year`*

        TODO: FIX TIME PERIODS
        &#34;&#34;&#34;
        if period == &#34;month&#34;:
            dates = self.data[&#34;statusdate&#34;].dt.month.astype(&#34;Int64&#34;)
            date_counts = dates.value_counts()
            date_counts = date_counts.sort_index()

            date_counts.index = pd.Index(
                [
                    &#34;Jan&#34;,
                    &#34;Feb&#34;,
                    &#34;Mar&#34;,
                    &#34;Apr&#34;,
                    &#34;May&#34;,
                    &#34;Jun&#34;,
                    &#34;Jul&#34;,
                    &#34;Aug&#34;,
                    &#34;Sep&#34;,
                    &#34;Oct&#34;,
                    &#34;Nov&#34;,
                    &#34;Dec&#34;,
                ]
            )

        if period == &#34;year&#34;:
            dates = self.data[&#34;statusdate&#34;].dt.year.astype(&#34;Int64&#34;)

            date_counts = dates.value_counts()
            date_counts = date_counts.sort_index()

            if num_years &gt; len(date_counts):
                raise &#34;The number of years must be less than the number of available years in the dataset&#34;

            if num_years &gt; step &gt;= 0:
                date_counts = date_counts.sort_index(ascending=False)

                years = []

                for i in range(0, num_years, step):
                    start = i
                    end = start + step

                    if len(date_counts) &gt; end:
                        end = len(date_counts) - 1

                    year_range = date_counts.iloc[i : i + step].sort_index()
                    years.append(year_range)

                return list(reversed(years))

        return date_counts

    def get_feature_occurrences_by_building(
        self,
        building_id: int,
        by: Union[List[str], str],
        find_all: bool = False,
        n: int = 10,
        warning: bool = False,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;
        Returns a list of the most common features provided in the brownsville.csv dataset.

        Parameters:
        -----------
        building_id: `int`
            Building ID to filter the results.
        by: `[str] | str`
            Column name or list of column names to filter the building complaints records by.
        find_all: `bool`
            Flag indicating whether to return all results for the provided feaures. Default False.
        n: `int`
            Number of maximum records to be returned by building. Default 10.
        warning: `bool`
            Set to `True` to display warning messages. Default False.
        &#34;&#34;&#34;

        # No maximum record limit is set and the find_all flag is set to false
        if n &lt; 1 and not find_all:
            raise &#34;n must greater than or equal to 1.&#34;

        # No column name(s) were provided
        if not by:
            raise &#34;You must specify a feature name.&#34;

        # If column name is a string, convert to a list of strings for convenience
        if isinstance(by, str):
            by = [by]

        # Filter the feature by BuildingID
        df_filter = self.data[&#34;buildingid&#34;] == building_id
        common_categories = self.data[df_filter][by].value_counts()

        if not find_all:
            # Limit the size of the common_categories series to n.
            # If n exceeds the size of common_categories, change n to be this szie.
            if n &gt; len(common_categories):
                n = len(common_categories)
                if warning:
                    print(&#34;n exceeds number of categories. Changing n to&#34;, n)

            common_categories = common_categories[:n]
        return common_categories

    def get_feature_occurrences_by_key(
        self,
        keys: Union[List[str], str],
        values: List[Any],
        features: Union[List[str], str],
        find_all: bool = False,
        n: int = 10,
        warning: bool = False,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;
        Returns a list of the most common features provided in the brownsville.csv dataset.

        Parameters:
        -----------
        keys: `List[str] | str`
            Building ID to filter the results.
        values: `List[Any]`
            Values to filter the keys by.
        features: `[str] | str`
            Column name or list of column names to filter the building complaints records by.
        find_all: `bool`
            Flag indicating whether to return all results for the provided feaures. Default False.
        n: `int`
            Number of maximum records to be returned by building. Default 10.
        warning: `bool`
            Set to `True` to display warning messages. Default False.
        &#34;&#34;&#34;

        # No maximum record limit is set and the find_all flag is set to false
        if n &lt; 1 and not find_all:
            raise &#34;n must greater than or equal to 1.&#34;

        # No column name(s) were provided
        if not features:
            raise &#34;You must specify a feature name.&#34;

        # If column name is a string, convert to a list of strings for convenience
        if isinstance(keys, str):
            keys = [keys]

        if isinstance(values, str):
            values = [values]

        if isinstance(features, str):
            features = [features]

        if len(keys) != len(values):
            raise &#34;Keys and Values should have the same number of elements.&#34;

        # Filter the feature by BuildingID
        filters = None
        for key, value in zip(keys, values):
            if filters is None:
                filters = self.data[key] == value
            else:
                filters &amp;= self.data[key] == value

        common_categories = self.data[filters][features].value_counts()

        if not find_all:
            # Limit the size of the common_categories series to n.
            # If n exceeds the size of common_categories, change n to be this szie.
            if n &gt; len(common_categories):
                n = len(common_categories)
                if warning:
                    print(&#34;n exceeds number of categories. Changing n to&#34;, n)

            common_categories = common_categories[:n]
        return common_categories

    def complaint_number(self, building_id: int) -&gt; int:
        &#34;&#34;&#34;
        Get the number of complaints reported for the specified building.

        Parameters:
        -----------
        building_id: `int`
            ID of the building in the dataset.
        &#34;&#34;&#34;
        # common_complaints = self.get_feature_occurrences_by_building(
        #     building_id, by=[&#34;majorcategory&#34;, &#34;minorcategory&#34;], find_all=True
        # )

        # return int(common_complaints.values.sum())
        return (self.data[&#34;buildingid&#34;] == building_id).sum()

    def get_common_complaint_categories(self, building_id: int) -&gt; int:
        &#34;&#34;&#34;
        Get the most common major and minor complaint category

        Parameters:
        -----------
        building_id: `int`
            ID of the building in the dataset.
        &#34;&#34;&#34;
        common_complaints = self.get_feature_occurrences_by_building(
            building_id, by=[&#34;majorcategory&#34;, &#34;minorcategory&#34;], find_all=True
        )
        if len(common_complaints) == 0:
            return (&#34;n/a&#34;, &#34;&#34;)

        return common_complaints.index[0]

    def save(self, filename: str = None, overwrite_file: bool = False) -&gt; None:
        &#34;&#34;&#34;
        Saves the current state of the dataset as a `.csv` file at the path specified during
        class instantiation.

        Parameters:
        -----------
        filename: `str`
            Name for the file being stored.
        force_save: `bool`
            Flag indicating whether the file should be overwritten or not.
        &#34;&#34;&#34;
        if not filename:
            filename = self.path + &#34;brownsville.csv&#34;

        if os.path.exists(filename):
            if not overwrite_file:
                inp = input(&#34;File already exists. Type y/Y to overwrite: &#34;)
                if inp.lower() != &#34;y&#34;:
                    return

        self.data.to_csv(filename)

    def display_map(self, save_map: bool = False) -&gt; folium.Map:
        &#34;&#34;&#34;
        Returns a folium map with information about all the buildings.

        Parameters:
        -----------
        save_map: `bool`
            Save the map to an `.html` file.
        &#34;&#34;&#34;

        nyc_longitude, nyc_latitude = 40.68424658435642, -73.91630313916588

        nyc_map: folium.Map = folium.Map(
            location=[nyc_longitude, nyc_latitude],
            tooltip=&#34;Click for building information&#34;,
            tiles=&#34;OpenStreetMap&#34;,
            zoom_start=12,
        )

        columns = [&#34;buildingid&#34;, &#34;address&#34;, &#34;latitude&#34;, &#34;longitude&#34;]
        unique_addresses = self.data[columns].groupby(columns).size()

        two_year_filter = (self.data[&#34;statusdate&#34;].dt.year == max(self.data[&#34;statusdate&#34;].dt.year) - 2)
        data_two_years = self.data[two_year_filter][columns]
        unique_addresses_two_years = data_two_years.groupby(columns).size()

        five_year_filter = (self.data[&#34;statusdate&#34;].dt.year == max(self.data[&#34;statusdate&#34;].dt.year) - 5)
        data_five_years = self.data[five_year_filter][columns]
        unique_addresses_five_years = data_five_years.groupby(columns).size()

        # Import the map marker style
        nyc_map.get_root().header.add_child(CssLink(&#34;./assets/css/foliumStyle.css&#34;))

        self.__create_marker_cluster(
            unique_addresses,
            name=&#34;Address locations&#34;
        ).add_to(nyc_map)
        self.__create_marker_cluster(
            unique_addresses_two_years,
            name=&#34;Address locations (two years)&#34;
        ).add_to(nyc_map)
        self.__create_marker_cluster(
            unique_addresses_five_years,
            name=&#34;Address locations (five years)&#34;
        ).add_to(nyc_map)

        # Get the coordinates for each building
        lats = self.data[&#34;latitude&#34;].values
        lons = self.data[&#34;longitude&#34;].values

        # Calculate and 0-1 normalize heatmap weights
        complaints_per_building = self.complaints
        weight_f = lambda b_id: complaints_per_building[b_id]
        weights = self.data[&#34;buildingid&#34;].apply(weight_f).values
        weights = (weights - min(weights)) / (max(weights) - min(weights))

        folium.plugins.HeatMap(
            data=list(zip(lats, lons, weights)),
            name=&#34;Brownsville heat map&#34;,
            min_opacity=0.3,
            max_opacity=0.7,
        ).add_to(nyc_map)

        folium.LayerControl().add_to(nyc_map)

        # Save the map to an HTML file
        if save_map:
            filename = os.path.join(self.path, &#34;brownsville.html&#34;)
            nyc_map.save(outfile=filename)

        return nyc_map

    def __create_marker_cluster(
        self, df: pd.DataFrame, name: str = &#34;name not specified&#34;
    ) -&gt; folium.plugins.MarkerCluster:
        &#34;&#34;&#34;
        Accepts a Folium map in which custom leaflet marker cluster are added.

        Parameters:
        -----------
        df: `pd.DataFrame`
            Pandas DataFrame used as reference for the marker clusters.
        name: `str`
            Name of the marker cluster
        &#34;&#34;&#34;

        # load the icon creation function
        icon_create_function = &#34;&#34;
        with open(&#34;./static/js/iconCreateFunction.js&#34;, &#34;r&#34;) as f:
            icon_create_function = f.read()

        # Create and add the marker cluster to the folium map
        marker_cluster = folium.plugins.MarkerCluster(
            name=name, icon_create_function=icon_create_function
        )

        for building_id, address, latitude, longitude in df.index:

            number_of_reports = self.complaint_number(building_id)
            major_category, minor_category = self.get_common_complaint_categories(
                building_id
            )
            complaint = f&#34;{major_category.title()} - {minor_category.title()}&#34;
            iframe = folium.IFrame(
                html=f&#34;&#34;&#34;
                    &lt;b&gt;{address}&lt;/b&gt;
                    &lt;br&gt;
                    &lt;br&gt;
                    &lt;b&gt;Number of reports:&lt;/b&gt; {number_of_reports}
                    &lt;br&gt;
                    &lt;b&gt;Building ID:&lt;/b&gt; {building_id}
                    &lt;br&gt;
                    &lt;b&gt;Latitude:&lt;/b&gt; {latitude}
                    &lt;br&gt;
                    &lt;b&gt;Longitude:&lt;/b&gt; {longitude}
                    &lt;br&gt;
                    &lt;b&gt;Most frequent complaint:&lt;/b&gt; {complaint}

                    &lt;style&gt;
                        html * {{
                            font-size: 1em !important;
                            color: #000 !important;
                            font-family: Arial !important;
                        }}
                    &lt;/style&gt;
                &#34;&#34;&#34;
            )

            popup = folium.Popup(iframe, min_width=350, max_width=350, parse_html=True)

            marker = folium.Marker(
                location=[latitude, longitude],
                popup=address,
                icon_create_function=icon_create_function,
                tooltip=f&#34;{number_of_reports} reports&#34;,
                reports=float(number_of_reports),
            )

            popup.add_to(marker)
            marker.add_to(marker_cluster)

        return marker_cluster

    def __update_map(self):
        &#34;&#34;&#34;
        Helper function to update map when instantiating the class.
        &#34;&#34;&#34;
        self.display_map(save_map=True)

    def __filter_no_complaints(self) -&gt; None:
        &#34;&#34;&#34;
        Remove buildings from the dataset that do not have a major or minor
        complaint category defined.
        &#34;&#34;&#34;
        no_complaints_filter = (self.data[&#34;majorcategoryid&#34;].isna()) &amp; (
            self.data[&#34;minorcategoryid&#34;].isna()
        )
        self.data = self.data[~(no_complaints_filter)]

    def __get_spatial_information(self) -&gt; None:
        &#34;&#34;&#34;
        Uses the geocode custom API to fetch spatial information about
        the building (latitude and longitude).
        &#34;&#34;&#34;
        state = &#34;NY&#34;
        columns = [&#34;address&#34;, &#34;borough&#34;, &#34;zip&#34;]

        # Read the translation table from local storage if exists
        filename = self.path + &#34;address_table.json&#34;
        if os.path.exists(filename):
            with open(filename, &#34;r&#34;) as f:
                address_to_coord = json.load(f)
        else:
            unique_addresses = self.data[columns].groupby(columns).size()
            address_to_coord = {}
            for street, city, zip_code in unique_addresses.index:
                address = &#34; &#34;.join((street, city, str(zip_code)))
                coord = self.geocode_client.get_lat_lng(street, city, state, zip_code)
                address_to_coord[address] = coord

            with open(filename, &#34;w&#34;) as f:
                address_to_coord = json.dump(address_to_coord, f)

        num_of_addresses = self.data.shape[0]
        latitudes = np.zeros(num_of_addresses)
        longitudes = np.zeros(num_of_addresses)

        for i, value in enumerate(self.data[columns].iterrows()):

            street, city, zip_code = value[1]
            address = &#34; &#34;.join((street, city, str(zip_code)))
            lat, lng = address_to_coord[address]

            latitudes[i] = lat
            longitudes[i] = lng

        self.data[&#34;latitude&#34;] = latitudes
        self.data[&#34;longitude&#34;] = longitudes

    def __set_addresses(self) -&gt; None:
        &#34;&#34;&#34;
        Concatenates the house number and street name into a single columns.
        &#34;&#34;&#34;
        self.data[&#34;address&#34;] = self.data[&#34;housenumber&#34;] + &#34; &#34; + self.data[&#34;streetname&#34;]

    def __parse_datatypes(self) -&gt; None:
        &#34;&#34;&#34;
        Parses the dataset features to their appropiate datatypes.
        &#34;&#34;&#34;
        self.data[&#34;unittypeid&#34;] = self.data[&#34;unittypeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;spacetypeid&#34;] = self.data[&#34;spacetypeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;typeid&#34;] = self.data[&#34;typeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;majorcategoryid&#34;] = self.data[&#34;majorcategoryid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;minorcategoryid&#34;] = self.data[&#34;minorcategoryid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;codeid&#34;] = self.data[&#34;codeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;receiveddate&#34;] = self.data[&#34;receiveddate&#34;].astype(&#34;datetime64&#34;)
        self.data[&#34;statusdate&#34;] = self.data[&#34;statusdate&#34;].astype(&#34;datetime64&#34;)

    def __load_dataset(self, force_load: bool = False) -&gt; None:
        &#34;&#34;&#34;
        Uses the Scoracte API custom client to create the Bronwsville dataset.
        &#34;&#34;&#34;

        with Client(*self.config[&#34;sodapy&#34;].values(), data_path=self.path) as c:

            update_due = (
                c.metadata_complaint_problems.cache_date
                &lt; c.metadata_complaint_problems.updated_on
            ) or (
                c.metadata_housing_maintenance.cache_date
                &lt; c.metadata_housing_maintenance.updated_on
            )

            filepath = os.path.join(self.path, c.metadata_brownsville.filename)
            if not force_load and not update_due and os.path.exists(filepath):
                print(&#34;Loading cached dataset...&#34;)
                self.data = pd.read_csv(filepath, index_col=0)
            else:
                self.data = c.load_brownsville(fetch_all=True)

    def __translate_ids(self) -&gt; None:
        &#34;&#34;&#34;
        Translate the feature id (i.e., majorcategoryid) to their corresponding value.
        &#34;&#34;&#34;
        with open(&#34;./brownsville_translations.yaml&#34;, &#34;r&#34;) as f:
            translations = yaml.load(f, Loader=yaml.FullLoader)
            for key in translations:
                value = translations[key]
                self.data[key] = self.data[key + &#34;id&#34;].map(value)

    def __load_config(self) -&gt; None:
        &#34;&#34;&#34;
        Load the configuration file necessary for the API&#39;s
        &#34;&#34;&#34;
        try:
            # Load the configuration files with all the credentials for the Socrata API
            with open(&#34;./config.yaml&#34;, &#34;r&#34;) as f:
                config = yaml.load(f, Loader=yaml.FullLoader)
                # app_token, username, password = config[&#34;sodapy&#34;].values()

                # if &#34;sodapy&#34; in config:
                #     app_token, username, password = config[&#34;sodapy&#34;].values()
                #     return app_token, username, password

                return config
        except FileNotFoundError:
            print(
                &#34;Configuration file not found. Loading client with default arguments.&#34;
            )
            return ()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="Brownsville.BrownsvilleAPI.Brownsville"><code class="flex name class">
<span>class <span class="ident">Brownsville</span></span>
<span>(</span><span>path: str = './data/brownsville/', force_load: bool = False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Brownsville:
    def __init__(
        self, path: str = &#34;./data/brownsville/&#34;, force_load: bool = False
    ) -&gt; None:
        self.path = path

        # Create the directory where the dataset will be stored
        if not os.path.exists(self.path):
            os.mkdir(self.path)

        self.config = self.__load_config()
        self.geocode_client = GeocodeClient(self.config[&#34;geocode&#34;][&#34;app_token&#34;])

        self.__load_dataset(force_load)
        self.__translate_ids()
        self.__parse_datatypes()
        self.__set_addresses()

        self.__get_spatial_information()

        # self.__filter_no_complaints()

        self._map = self.__update_map()

    @property
    def buildings(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Returns an NumPy ndarray with the set of unique buildings in the dataset by building id.
        &#34;&#34;&#34;
        return self.data[&#34;buildingid&#34;].unique()

    @property
    def complaints(self) -&gt; pd.Series:
        &#34;&#34;&#34;
        Returns a Pandas DataFrame with building_id&#39;s and their respective
        number of complaints reported.
        &#34;&#34;&#34;

        # complaints = np.zeros(len(self.buildings))
        # for i, building_id in enumerate(self.buildings):
        #     num_of_complaints = self.complaint_number(building_id)
        #     complaints[i] = num_of_complaints

        # df = pd.DataFrame({&#34;buildingid&#34;: self.buildings, &#34;complaints&#34;: complaints})

        # return df
        return self.data[&#34;buildingid&#34;].value_counts()

    def get_date_range(self, by: str = &#34;status&#34;) -&gt; Tuple[pd.Timestamp, pd.Timestamp]:
        &#34;&#34;&#34;
        Return the date range for the complaint since the day it was marked as complete or
        since the day it was received.

        Parameters:
        -----------
        by: `str`
            Feature to get the data range by.
        &#34;&#34;&#34;
        if by not in (&#34;status&#34;, &#34;received&#34;):
            raise InvalidColumnNameError()

        by += &#34;date&#34;

        return self.data[by].min(), self.data[by].max()

    def records_by_season(self) -&gt; Tuple[List, List]:
        &#34;&#34;&#34;
        Return the number of complaints reported by season.
        &#34;&#34;&#34;
        date_counts = self.records_by_date(period=&#34;month&#34;)

        seasons = [&#34;Winter&#34;, &#34;Spring&#34;, &#34;Summer&#34;, &#34;Autumn&#34;]
        values = [
            date_counts.loc[[&#34;Jan&#34;, &#34;Feb&#34;, &#34;Mar&#34;]].sum(),
            date_counts.loc[[&#34;Apr&#34;, &#34;May&#34;, &#34;Jun&#34;]].sum(),
            date_counts.loc[[&#34;Jul&#34;, &#34;Aug&#34;, &#34;Sep&#34;]].sum(),
            date_counts.loc[[&#34;Oct&#34;, &#34;Nov&#34;, &#34;Dec&#34;]].sum(),
        ]
        print(f&#34;{seasons[0]}: {values[0]}&#34;)
        print(f&#34;{seasons[1]}: {values[1]}&#34;)
        print(f&#34;{seasons[2]}: {values[2]}&#34;)
        print(f&#34;{seasons[3]}: {values[3]}&#34;)

        return seasons, values

    def records_by_date(
        self, period: str = &#34;month&#34;, step: int = 1, num_years: int = 0
    ) -&gt; set:
        &#34;&#34;&#34;
        Return the number of complaints reported on a monthly or yearly basis.

        Parameters:
        -----------
        period: `str`
            Type of time period to return the number of complaint reported.
        step: `int`
            Number of year intervals to separate the data. *Only works if period is `year`*
        num_years `int`
            Number of past years to query the data. *Only works if period is `year`*

        TODO: FIX TIME PERIODS
        &#34;&#34;&#34;
        if period == &#34;month&#34;:
            dates = self.data[&#34;statusdate&#34;].dt.month.astype(&#34;Int64&#34;)
            date_counts = dates.value_counts()
            date_counts = date_counts.sort_index()

            date_counts.index = pd.Index(
                [
                    &#34;Jan&#34;,
                    &#34;Feb&#34;,
                    &#34;Mar&#34;,
                    &#34;Apr&#34;,
                    &#34;May&#34;,
                    &#34;Jun&#34;,
                    &#34;Jul&#34;,
                    &#34;Aug&#34;,
                    &#34;Sep&#34;,
                    &#34;Oct&#34;,
                    &#34;Nov&#34;,
                    &#34;Dec&#34;,
                ]
            )

        if period == &#34;year&#34;:
            dates = self.data[&#34;statusdate&#34;].dt.year.astype(&#34;Int64&#34;)

            date_counts = dates.value_counts()
            date_counts = date_counts.sort_index()

            if num_years &gt; len(date_counts):
                raise &#34;The number of years must be less than the number of available years in the dataset&#34;

            if num_years &gt; step &gt;= 0:
                date_counts = date_counts.sort_index(ascending=False)

                years = []

                for i in range(0, num_years, step):
                    start = i
                    end = start + step

                    if len(date_counts) &gt; end:
                        end = len(date_counts) - 1

                    year_range = date_counts.iloc[i : i + step].sort_index()
                    years.append(year_range)

                return list(reversed(years))

        return date_counts

    def get_feature_occurrences_by_building(
        self,
        building_id: int,
        by: Union[List[str], str],
        find_all: bool = False,
        n: int = 10,
        warning: bool = False,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;
        Returns a list of the most common features provided in the brownsville.csv dataset.

        Parameters:
        -----------
        building_id: `int`
            Building ID to filter the results.
        by: `[str] | str`
            Column name or list of column names to filter the building complaints records by.
        find_all: `bool`
            Flag indicating whether to return all results for the provided feaures. Default False.
        n: `int`
            Number of maximum records to be returned by building. Default 10.
        warning: `bool`
            Set to `True` to display warning messages. Default False.
        &#34;&#34;&#34;

        # No maximum record limit is set and the find_all flag is set to false
        if n &lt; 1 and not find_all:
            raise &#34;n must greater than or equal to 1.&#34;

        # No column name(s) were provided
        if not by:
            raise &#34;You must specify a feature name.&#34;

        # If column name is a string, convert to a list of strings for convenience
        if isinstance(by, str):
            by = [by]

        # Filter the feature by BuildingID
        df_filter = self.data[&#34;buildingid&#34;] == building_id
        common_categories = self.data[df_filter][by].value_counts()

        if not find_all:
            # Limit the size of the common_categories series to n.
            # If n exceeds the size of common_categories, change n to be this szie.
            if n &gt; len(common_categories):
                n = len(common_categories)
                if warning:
                    print(&#34;n exceeds number of categories. Changing n to&#34;, n)

            common_categories = common_categories[:n]
        return common_categories

    def get_feature_occurrences_by_key(
        self,
        keys: Union[List[str], str],
        values: List[Any],
        features: Union[List[str], str],
        find_all: bool = False,
        n: int = 10,
        warning: bool = False,
    ) -&gt; pd.Series:
        &#34;&#34;&#34;
        Returns a list of the most common features provided in the brownsville.csv dataset.

        Parameters:
        -----------
        keys: `List[str] | str`
            Building ID to filter the results.
        values: `List[Any]`
            Values to filter the keys by.
        features: `[str] | str`
            Column name or list of column names to filter the building complaints records by.
        find_all: `bool`
            Flag indicating whether to return all results for the provided feaures. Default False.
        n: `int`
            Number of maximum records to be returned by building. Default 10.
        warning: `bool`
            Set to `True` to display warning messages. Default False.
        &#34;&#34;&#34;

        # No maximum record limit is set and the find_all flag is set to false
        if n &lt; 1 and not find_all:
            raise &#34;n must greater than or equal to 1.&#34;

        # No column name(s) were provided
        if not features:
            raise &#34;You must specify a feature name.&#34;

        # If column name is a string, convert to a list of strings for convenience
        if isinstance(keys, str):
            keys = [keys]

        if isinstance(values, str):
            values = [values]

        if isinstance(features, str):
            features = [features]

        if len(keys) != len(values):
            raise &#34;Keys and Values should have the same number of elements.&#34;

        # Filter the feature by BuildingID
        filters = None
        for key, value in zip(keys, values):
            if filters is None:
                filters = self.data[key] == value
            else:
                filters &amp;= self.data[key] == value

        common_categories = self.data[filters][features].value_counts()

        if not find_all:
            # Limit the size of the common_categories series to n.
            # If n exceeds the size of common_categories, change n to be this szie.
            if n &gt; len(common_categories):
                n = len(common_categories)
                if warning:
                    print(&#34;n exceeds number of categories. Changing n to&#34;, n)

            common_categories = common_categories[:n]
        return common_categories

    def complaint_number(self, building_id: int) -&gt; int:
        &#34;&#34;&#34;
        Get the number of complaints reported for the specified building.

        Parameters:
        -----------
        building_id: `int`
            ID of the building in the dataset.
        &#34;&#34;&#34;
        # common_complaints = self.get_feature_occurrences_by_building(
        #     building_id, by=[&#34;majorcategory&#34;, &#34;minorcategory&#34;], find_all=True
        # )

        # return int(common_complaints.values.sum())
        return (self.data[&#34;buildingid&#34;] == building_id).sum()

    def get_common_complaint_categories(self, building_id: int) -&gt; int:
        &#34;&#34;&#34;
        Get the most common major and minor complaint category

        Parameters:
        -----------
        building_id: `int`
            ID of the building in the dataset.
        &#34;&#34;&#34;
        common_complaints = self.get_feature_occurrences_by_building(
            building_id, by=[&#34;majorcategory&#34;, &#34;minorcategory&#34;], find_all=True
        )
        if len(common_complaints) == 0:
            return (&#34;n/a&#34;, &#34;&#34;)

        return common_complaints.index[0]

    def save(self, filename: str = None, overwrite_file: bool = False) -&gt; None:
        &#34;&#34;&#34;
        Saves the current state of the dataset as a `.csv` file at the path specified during
        class instantiation.

        Parameters:
        -----------
        filename: `str`
            Name for the file being stored.
        force_save: `bool`
            Flag indicating whether the file should be overwritten or not.
        &#34;&#34;&#34;
        if not filename:
            filename = self.path + &#34;brownsville.csv&#34;

        if os.path.exists(filename):
            if not overwrite_file:
                inp = input(&#34;File already exists. Type y/Y to overwrite: &#34;)
                if inp.lower() != &#34;y&#34;:
                    return

        self.data.to_csv(filename)

    def display_map(self, save_map: bool = False) -&gt; folium.Map:
        &#34;&#34;&#34;
        Returns a folium map with information about all the buildings.

        Parameters:
        -----------
        save_map: `bool`
            Save the map to an `.html` file.
        &#34;&#34;&#34;

        nyc_longitude, nyc_latitude = 40.68424658435642, -73.91630313916588

        nyc_map: folium.Map = folium.Map(
            location=[nyc_longitude, nyc_latitude],
            tooltip=&#34;Click for building information&#34;,
            tiles=&#34;OpenStreetMap&#34;,
            zoom_start=12,
        )

        columns = [&#34;buildingid&#34;, &#34;address&#34;, &#34;latitude&#34;, &#34;longitude&#34;]
        unique_addresses = self.data[columns].groupby(columns).size()

        two_year_filter = (self.data[&#34;statusdate&#34;].dt.year == max(self.data[&#34;statusdate&#34;].dt.year) - 2)
        data_two_years = self.data[two_year_filter][columns]
        unique_addresses_two_years = data_two_years.groupby(columns).size()

        five_year_filter = (self.data[&#34;statusdate&#34;].dt.year == max(self.data[&#34;statusdate&#34;].dt.year) - 5)
        data_five_years = self.data[five_year_filter][columns]
        unique_addresses_five_years = data_five_years.groupby(columns).size()

        # Import the map marker style
        nyc_map.get_root().header.add_child(CssLink(&#34;./assets/css/foliumStyle.css&#34;))

        self.__create_marker_cluster(
            unique_addresses,
            name=&#34;Address locations&#34;
        ).add_to(nyc_map)
        self.__create_marker_cluster(
            unique_addresses_two_years,
            name=&#34;Address locations (two years)&#34;
        ).add_to(nyc_map)
        self.__create_marker_cluster(
            unique_addresses_five_years,
            name=&#34;Address locations (five years)&#34;
        ).add_to(nyc_map)

        # Get the coordinates for each building
        lats = self.data[&#34;latitude&#34;].values
        lons = self.data[&#34;longitude&#34;].values

        # Calculate and 0-1 normalize heatmap weights
        complaints_per_building = self.complaints
        weight_f = lambda b_id: complaints_per_building[b_id]
        weights = self.data[&#34;buildingid&#34;].apply(weight_f).values
        weights = (weights - min(weights)) / (max(weights) - min(weights))

        folium.plugins.HeatMap(
            data=list(zip(lats, lons, weights)),
            name=&#34;Brownsville heat map&#34;,
            min_opacity=0.3,
            max_opacity=0.7,
        ).add_to(nyc_map)

        folium.LayerControl().add_to(nyc_map)

        # Save the map to an HTML file
        if save_map:
            filename = os.path.join(self.path, &#34;brownsville.html&#34;)
            nyc_map.save(outfile=filename)

        return nyc_map

    def __create_marker_cluster(
        self, df: pd.DataFrame, name: str = &#34;name not specified&#34;
    ) -&gt; folium.plugins.MarkerCluster:
        &#34;&#34;&#34;
        Accepts a Folium map in which custom leaflet marker cluster are added.

        Parameters:
        -----------
        df: `pd.DataFrame`
            Pandas DataFrame used as reference for the marker clusters.
        name: `str`
            Name of the marker cluster
        &#34;&#34;&#34;

        # load the icon creation function
        icon_create_function = &#34;&#34;
        with open(&#34;./static/js/iconCreateFunction.js&#34;, &#34;r&#34;) as f:
            icon_create_function = f.read()

        # Create and add the marker cluster to the folium map
        marker_cluster = folium.plugins.MarkerCluster(
            name=name, icon_create_function=icon_create_function
        )

        for building_id, address, latitude, longitude in df.index:

            number_of_reports = self.complaint_number(building_id)
            major_category, minor_category = self.get_common_complaint_categories(
                building_id
            )
            complaint = f&#34;{major_category.title()} - {minor_category.title()}&#34;
            iframe = folium.IFrame(
                html=f&#34;&#34;&#34;
                    &lt;b&gt;{address}&lt;/b&gt;
                    &lt;br&gt;
                    &lt;br&gt;
                    &lt;b&gt;Number of reports:&lt;/b&gt; {number_of_reports}
                    &lt;br&gt;
                    &lt;b&gt;Building ID:&lt;/b&gt; {building_id}
                    &lt;br&gt;
                    &lt;b&gt;Latitude:&lt;/b&gt; {latitude}
                    &lt;br&gt;
                    &lt;b&gt;Longitude:&lt;/b&gt; {longitude}
                    &lt;br&gt;
                    &lt;b&gt;Most frequent complaint:&lt;/b&gt; {complaint}

                    &lt;style&gt;
                        html * {{
                            font-size: 1em !important;
                            color: #000 !important;
                            font-family: Arial !important;
                        }}
                    &lt;/style&gt;
                &#34;&#34;&#34;
            )

            popup = folium.Popup(iframe, min_width=350, max_width=350, parse_html=True)

            marker = folium.Marker(
                location=[latitude, longitude],
                popup=address,
                icon_create_function=icon_create_function,
                tooltip=f&#34;{number_of_reports} reports&#34;,
                reports=float(number_of_reports),
            )

            popup.add_to(marker)
            marker.add_to(marker_cluster)

        return marker_cluster

    def __update_map(self):
        &#34;&#34;&#34;
        Helper function to update map when instantiating the class.
        &#34;&#34;&#34;
        self.display_map(save_map=True)

    def __filter_no_complaints(self) -&gt; None:
        &#34;&#34;&#34;
        Remove buildings from the dataset that do not have a major or minor
        complaint category defined.
        &#34;&#34;&#34;
        no_complaints_filter = (self.data[&#34;majorcategoryid&#34;].isna()) &amp; (
            self.data[&#34;minorcategoryid&#34;].isna()
        )
        self.data = self.data[~(no_complaints_filter)]

    def __get_spatial_information(self) -&gt; None:
        &#34;&#34;&#34;
        Uses the geocode custom API to fetch spatial information about
        the building (latitude and longitude).
        &#34;&#34;&#34;
        state = &#34;NY&#34;
        columns = [&#34;address&#34;, &#34;borough&#34;, &#34;zip&#34;]

        # Read the translation table from local storage if exists
        filename = self.path + &#34;address_table.json&#34;
        if os.path.exists(filename):
            with open(filename, &#34;r&#34;) as f:
                address_to_coord = json.load(f)
        else:
            unique_addresses = self.data[columns].groupby(columns).size()
            address_to_coord = {}
            for street, city, zip_code in unique_addresses.index:
                address = &#34; &#34;.join((street, city, str(zip_code)))
                coord = self.geocode_client.get_lat_lng(street, city, state, zip_code)
                address_to_coord[address] = coord

            with open(filename, &#34;w&#34;) as f:
                address_to_coord = json.dump(address_to_coord, f)

        num_of_addresses = self.data.shape[0]
        latitudes = np.zeros(num_of_addresses)
        longitudes = np.zeros(num_of_addresses)

        for i, value in enumerate(self.data[columns].iterrows()):

            street, city, zip_code = value[1]
            address = &#34; &#34;.join((street, city, str(zip_code)))
            lat, lng = address_to_coord[address]

            latitudes[i] = lat
            longitudes[i] = lng

        self.data[&#34;latitude&#34;] = latitudes
        self.data[&#34;longitude&#34;] = longitudes

    def __set_addresses(self) -&gt; None:
        &#34;&#34;&#34;
        Concatenates the house number and street name into a single columns.
        &#34;&#34;&#34;
        self.data[&#34;address&#34;] = self.data[&#34;housenumber&#34;] + &#34; &#34; + self.data[&#34;streetname&#34;]

    def __parse_datatypes(self) -&gt; None:
        &#34;&#34;&#34;
        Parses the dataset features to their appropiate datatypes.
        &#34;&#34;&#34;
        self.data[&#34;unittypeid&#34;] = self.data[&#34;unittypeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;spacetypeid&#34;] = self.data[&#34;spacetypeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;typeid&#34;] = self.data[&#34;typeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;majorcategoryid&#34;] = self.data[&#34;majorcategoryid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;minorcategoryid&#34;] = self.data[&#34;minorcategoryid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;codeid&#34;] = self.data[&#34;codeid&#34;].astype(&#34;Int64&#34;)
        self.data[&#34;receiveddate&#34;] = self.data[&#34;receiveddate&#34;].astype(&#34;datetime64&#34;)
        self.data[&#34;statusdate&#34;] = self.data[&#34;statusdate&#34;].astype(&#34;datetime64&#34;)

    def __load_dataset(self, force_load: bool = False) -&gt; None:
        &#34;&#34;&#34;
        Uses the Scoracte API custom client to create the Bronwsville dataset.
        &#34;&#34;&#34;

        with Client(*self.config[&#34;sodapy&#34;].values(), data_path=self.path) as c:

            update_due = (
                c.metadata_complaint_problems.cache_date
                &lt; c.metadata_complaint_problems.updated_on
            ) or (
                c.metadata_housing_maintenance.cache_date
                &lt; c.metadata_housing_maintenance.updated_on
            )

            filepath = os.path.join(self.path, c.metadata_brownsville.filename)
            if not force_load and not update_due and os.path.exists(filepath):
                print(&#34;Loading cached dataset...&#34;)
                self.data = pd.read_csv(filepath, index_col=0)
            else:
                self.data = c.load_brownsville(fetch_all=True)

    def __translate_ids(self) -&gt; None:
        &#34;&#34;&#34;
        Translate the feature id (i.e., majorcategoryid) to their corresponding value.
        &#34;&#34;&#34;
        with open(&#34;./brownsville_translations.yaml&#34;, &#34;r&#34;) as f:
            translations = yaml.load(f, Loader=yaml.FullLoader)
            for key in translations:
                value = translations[key]
                self.data[key] = self.data[key + &#34;id&#34;].map(value)

    def __load_config(self) -&gt; None:
        &#34;&#34;&#34;
        Load the configuration file necessary for the API&#39;s
        &#34;&#34;&#34;
        try:
            # Load the configuration files with all the credentials for the Socrata API
            with open(&#34;./config.yaml&#34;, &#34;r&#34;) as f:
                config = yaml.load(f, Loader=yaml.FullLoader)
                # app_token, username, password = config[&#34;sodapy&#34;].values()

                # if &#34;sodapy&#34; in config:
                #     app_token, username, password = config[&#34;sodapy&#34;].values()
                #     return app_token, username, password

                return config
        except FileNotFoundError:
            print(
                &#34;Configuration file not found. Loading client with default arguments.&#34;
            )
            return ()</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.buildings"><code class="name">var <span class="ident">buildings</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"><p>Returns an NumPy ndarray with the set of unique buildings in the dataset by building id.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def buildings(self) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Returns an NumPy ndarray with the set of unique buildings in the dataset by building id.
    &#34;&#34;&#34;
    return self.data[&#34;buildingid&#34;].unique()</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.complaints"><code class="name">var <span class="ident">complaints</span> : pandas.core.series.Series</code></dt>
<dd>
<div class="desc"><p>Returns a Pandas DataFrame with building_id's and their respective
number of complaints reported.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def complaints(self) -&gt; pd.Series:
    &#34;&#34;&#34;
    Returns a Pandas DataFrame with building_id&#39;s and their respective
    number of complaints reported.
    &#34;&#34;&#34;

    # complaints = np.zeros(len(self.buildings))
    # for i, building_id in enumerate(self.buildings):
    #     num_of_complaints = self.complaint_number(building_id)
    #     complaints[i] = num_of_complaints

    # df = pd.DataFrame({&#34;buildingid&#34;: self.buildings, &#34;complaints&#34;: complaints})

    # return df
    return self.data[&#34;buildingid&#34;].value_counts()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.complaint_number"><code class="name flex">
<span>def <span class="ident">complaint_number</span></span>(<span>self, building_id: int) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Get the number of complaints reported for the specified building.</p>
<h2 id="parameters">Parameters:</h2>
<p>building_id: <code>int</code>
ID of the building in the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def complaint_number(self, building_id: int) -&gt; int:
    &#34;&#34;&#34;
    Get the number of complaints reported for the specified building.

    Parameters:
    -----------
    building_id: `int`
        ID of the building in the dataset.
    &#34;&#34;&#34;
    # common_complaints = self.get_feature_occurrences_by_building(
    #     building_id, by=[&#34;majorcategory&#34;, &#34;minorcategory&#34;], find_all=True
    # )

    # return int(common_complaints.values.sum())
    return (self.data[&#34;buildingid&#34;] == building_id).sum()</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.display_map"><code class="name flex">
<span>def <span class="ident">display_map</span></span>(<span>self, save_map: bool = False) ‑> folium.folium.Map</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a folium map with information about all the buildings.</p>
<h2 id="parameters">Parameters:</h2>
<p>save_map: <code>bool</code>
Save the map to an <code>.html</code> file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display_map(self, save_map: bool = False) -&gt; folium.Map:
    &#34;&#34;&#34;
    Returns a folium map with information about all the buildings.

    Parameters:
    -----------
    save_map: `bool`
        Save the map to an `.html` file.
    &#34;&#34;&#34;

    nyc_longitude, nyc_latitude = 40.68424658435642, -73.91630313916588

    nyc_map: folium.Map = folium.Map(
        location=[nyc_longitude, nyc_latitude],
        tooltip=&#34;Click for building information&#34;,
        tiles=&#34;OpenStreetMap&#34;,
        zoom_start=12,
    )

    columns = [&#34;buildingid&#34;, &#34;address&#34;, &#34;latitude&#34;, &#34;longitude&#34;]
    unique_addresses = self.data[columns].groupby(columns).size()

    two_year_filter = (self.data[&#34;statusdate&#34;].dt.year == max(self.data[&#34;statusdate&#34;].dt.year) - 2)
    data_two_years = self.data[two_year_filter][columns]
    unique_addresses_two_years = data_two_years.groupby(columns).size()

    five_year_filter = (self.data[&#34;statusdate&#34;].dt.year == max(self.data[&#34;statusdate&#34;].dt.year) - 5)
    data_five_years = self.data[five_year_filter][columns]
    unique_addresses_five_years = data_five_years.groupby(columns).size()

    # Import the map marker style
    nyc_map.get_root().header.add_child(CssLink(&#34;./assets/css/foliumStyle.css&#34;))

    self.__create_marker_cluster(
        unique_addresses,
        name=&#34;Address locations&#34;
    ).add_to(nyc_map)
    self.__create_marker_cluster(
        unique_addresses_two_years,
        name=&#34;Address locations (two years)&#34;
    ).add_to(nyc_map)
    self.__create_marker_cluster(
        unique_addresses_five_years,
        name=&#34;Address locations (five years)&#34;
    ).add_to(nyc_map)

    # Get the coordinates for each building
    lats = self.data[&#34;latitude&#34;].values
    lons = self.data[&#34;longitude&#34;].values

    # Calculate and 0-1 normalize heatmap weights
    complaints_per_building = self.complaints
    weight_f = lambda b_id: complaints_per_building[b_id]
    weights = self.data[&#34;buildingid&#34;].apply(weight_f).values
    weights = (weights - min(weights)) / (max(weights) - min(weights))

    folium.plugins.HeatMap(
        data=list(zip(lats, lons, weights)),
        name=&#34;Brownsville heat map&#34;,
        min_opacity=0.3,
        max_opacity=0.7,
    ).add_to(nyc_map)

    folium.LayerControl().add_to(nyc_map)

    # Save the map to an HTML file
    if save_map:
        filename = os.path.join(self.path, &#34;brownsville.html&#34;)
        nyc_map.save(outfile=filename)

    return nyc_map</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.get_common_complaint_categories"><code class="name flex">
<span>def <span class="ident">get_common_complaint_categories</span></span>(<span>self, building_id: int) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Get the most common major and minor complaint category</p>
<h2 id="parameters">Parameters:</h2>
<p>building_id: <code>int</code>
ID of the building in the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_common_complaint_categories(self, building_id: int) -&gt; int:
    &#34;&#34;&#34;
    Get the most common major and minor complaint category

    Parameters:
    -----------
    building_id: `int`
        ID of the building in the dataset.
    &#34;&#34;&#34;
    common_complaints = self.get_feature_occurrences_by_building(
        building_id, by=[&#34;majorcategory&#34;, &#34;minorcategory&#34;], find_all=True
    )
    if len(common_complaints) == 0:
        return (&#34;n/a&#34;, &#34;&#34;)

    return common_complaints.index[0]</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.get_date_range"><code class="name flex">
<span>def <span class="ident">get_date_range</span></span>(<span>self, by: str = 'status') ‑> Tuple[pandas._libs.tslibs.timestamps.Timestamp, pandas._libs.tslibs.timestamps.Timestamp]</span>
</code></dt>
<dd>
<div class="desc"><p>Return the date range for the complaint since the day it was marked as complete or
since the day it was received.</p>
<h2 id="parameters">Parameters:</h2>
<p>by: <code>str</code>
Feature to get the data range by.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_date_range(self, by: str = &#34;status&#34;) -&gt; Tuple[pd.Timestamp, pd.Timestamp]:
    &#34;&#34;&#34;
    Return the date range for the complaint since the day it was marked as complete or
    since the day it was received.

    Parameters:
    -----------
    by: `str`
        Feature to get the data range by.
    &#34;&#34;&#34;
    if by not in (&#34;status&#34;, &#34;received&#34;):
        raise InvalidColumnNameError()

    by += &#34;date&#34;

    return self.data[by].min(), self.data[by].max()</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.get_feature_occurrences_by_building"><code class="name flex">
<span>def <span class="ident">get_feature_occurrences_by_building</span></span>(<span>self, building_id: int, by: Union[List[str], str], find_all: bool = False, n: int = 10, warning: bool = False) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of the most common features provided in the brownsville.csv dataset.</p>
<h2 id="parameters">Parameters:</h2>
<p>building_id: <code>int</code>
Building ID to filter the results.
by: <code>[str] | str</code>
Column name or list of column names to filter the building complaints records by.
find_all: <code>bool</code>
Flag indicating whether to return all results for the provided feaures. Default False.
n: <code>int</code>
Number of maximum records to be returned by building. Default 10.
warning: <code>bool</code>
Set to <code>True</code> to display warning messages. Default False.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_feature_occurrences_by_building(
    self,
    building_id: int,
    by: Union[List[str], str],
    find_all: bool = False,
    n: int = 10,
    warning: bool = False,
) -&gt; pd.Series:
    &#34;&#34;&#34;
    Returns a list of the most common features provided in the brownsville.csv dataset.

    Parameters:
    -----------
    building_id: `int`
        Building ID to filter the results.
    by: `[str] | str`
        Column name or list of column names to filter the building complaints records by.
    find_all: `bool`
        Flag indicating whether to return all results for the provided feaures. Default False.
    n: `int`
        Number of maximum records to be returned by building. Default 10.
    warning: `bool`
        Set to `True` to display warning messages. Default False.
    &#34;&#34;&#34;

    # No maximum record limit is set and the find_all flag is set to false
    if n &lt; 1 and not find_all:
        raise &#34;n must greater than or equal to 1.&#34;

    # No column name(s) were provided
    if not by:
        raise &#34;You must specify a feature name.&#34;

    # If column name is a string, convert to a list of strings for convenience
    if isinstance(by, str):
        by = [by]

    # Filter the feature by BuildingID
    df_filter = self.data[&#34;buildingid&#34;] == building_id
    common_categories = self.data[df_filter][by].value_counts()

    if not find_all:
        # Limit the size of the common_categories series to n.
        # If n exceeds the size of common_categories, change n to be this szie.
        if n &gt; len(common_categories):
            n = len(common_categories)
            if warning:
                print(&#34;n exceeds number of categories. Changing n to&#34;, n)

        common_categories = common_categories[:n]
    return common_categories</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.get_feature_occurrences_by_key"><code class="name flex">
<span>def <span class="ident">get_feature_occurrences_by_key</span></span>(<span>self, keys: Union[List[str], str], values: List[Any], features: Union[List[str], str], find_all: bool = False, n: int = 10, warning: bool = False) ‑> pandas.core.series.Series</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of the most common features provided in the brownsville.csv dataset.</p>
<h2 id="parameters">Parameters:</h2>
<p>keys: <code>List[str] | str</code>
Building ID to filter the results.
values: <code>List[Any]</code>
Values to filter the keys by.
features: <code>[str] | str</code>
Column name or list of column names to filter the building complaints records by.
find_all: <code>bool</code>
Flag indicating whether to return all results for the provided feaures. Default False.
n: <code>int</code>
Number of maximum records to be returned by building. Default 10.
warning: <code>bool</code>
Set to <code>True</code> to display warning messages. Default False.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_feature_occurrences_by_key(
    self,
    keys: Union[List[str], str],
    values: List[Any],
    features: Union[List[str], str],
    find_all: bool = False,
    n: int = 10,
    warning: bool = False,
) -&gt; pd.Series:
    &#34;&#34;&#34;
    Returns a list of the most common features provided in the brownsville.csv dataset.

    Parameters:
    -----------
    keys: `List[str] | str`
        Building ID to filter the results.
    values: `List[Any]`
        Values to filter the keys by.
    features: `[str] | str`
        Column name or list of column names to filter the building complaints records by.
    find_all: `bool`
        Flag indicating whether to return all results for the provided feaures. Default False.
    n: `int`
        Number of maximum records to be returned by building. Default 10.
    warning: `bool`
        Set to `True` to display warning messages. Default False.
    &#34;&#34;&#34;

    # No maximum record limit is set and the find_all flag is set to false
    if n &lt; 1 and not find_all:
        raise &#34;n must greater than or equal to 1.&#34;

    # No column name(s) were provided
    if not features:
        raise &#34;You must specify a feature name.&#34;

    # If column name is a string, convert to a list of strings for convenience
    if isinstance(keys, str):
        keys = [keys]

    if isinstance(values, str):
        values = [values]

    if isinstance(features, str):
        features = [features]

    if len(keys) != len(values):
        raise &#34;Keys and Values should have the same number of elements.&#34;

    # Filter the feature by BuildingID
    filters = None
    for key, value in zip(keys, values):
        if filters is None:
            filters = self.data[key] == value
        else:
            filters &amp;= self.data[key] == value

    common_categories = self.data[filters][features].value_counts()

    if not find_all:
        # Limit the size of the common_categories series to n.
        # If n exceeds the size of common_categories, change n to be this szie.
        if n &gt; len(common_categories):
            n = len(common_categories)
            if warning:
                print(&#34;n exceeds number of categories. Changing n to&#34;, n)

        common_categories = common_categories[:n]
    return common_categories</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.records_by_date"><code class="name flex">
<span>def <span class="ident">records_by_date</span></span>(<span>self, period: str = 'month', step: int = 1, num_years: int = 0) ‑> set</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of complaints reported on a monthly or yearly basis.</p>
<h2 id="parameters">Parameters:</h2>
<p>period: <code>str</code>
Type of time period to return the number of complaint reported.
step: <code>int</code>
Number of year intervals to separate the data. <em>Only works if period is <code>year</code></em>
num_years <code>int</code>
Number of past years to query the data. <em>Only works if period is <code>year</code></em></p>
<p>TODO: FIX TIME PERIODS</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def records_by_date(
    self, period: str = &#34;month&#34;, step: int = 1, num_years: int = 0
) -&gt; set:
    &#34;&#34;&#34;
    Return the number of complaints reported on a monthly or yearly basis.

    Parameters:
    -----------
    period: `str`
        Type of time period to return the number of complaint reported.
    step: `int`
        Number of year intervals to separate the data. *Only works if period is `year`*
    num_years `int`
        Number of past years to query the data. *Only works if period is `year`*

    TODO: FIX TIME PERIODS
    &#34;&#34;&#34;
    if period == &#34;month&#34;:
        dates = self.data[&#34;statusdate&#34;].dt.month.astype(&#34;Int64&#34;)
        date_counts = dates.value_counts()
        date_counts = date_counts.sort_index()

        date_counts.index = pd.Index(
            [
                &#34;Jan&#34;,
                &#34;Feb&#34;,
                &#34;Mar&#34;,
                &#34;Apr&#34;,
                &#34;May&#34;,
                &#34;Jun&#34;,
                &#34;Jul&#34;,
                &#34;Aug&#34;,
                &#34;Sep&#34;,
                &#34;Oct&#34;,
                &#34;Nov&#34;,
                &#34;Dec&#34;,
            ]
        )

    if period == &#34;year&#34;:
        dates = self.data[&#34;statusdate&#34;].dt.year.astype(&#34;Int64&#34;)

        date_counts = dates.value_counts()
        date_counts = date_counts.sort_index()

        if num_years &gt; len(date_counts):
            raise &#34;The number of years must be less than the number of available years in the dataset&#34;

        if num_years &gt; step &gt;= 0:
            date_counts = date_counts.sort_index(ascending=False)

            years = []

            for i in range(0, num_years, step):
                start = i
                end = start + step

                if len(date_counts) &gt; end:
                    end = len(date_counts) - 1

                year_range = date_counts.iloc[i : i + step].sort_index()
                years.append(year_range)

            return list(reversed(years))

    return date_counts</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.records_by_season"><code class="name flex">
<span>def <span class="ident">records_by_season</span></span>(<span>self) ‑> Tuple[List, List]</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of complaints reported by season.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def records_by_season(self) -&gt; Tuple[List, List]:
    &#34;&#34;&#34;
    Return the number of complaints reported by season.
    &#34;&#34;&#34;
    date_counts = self.records_by_date(period=&#34;month&#34;)

    seasons = [&#34;Winter&#34;, &#34;Spring&#34;, &#34;Summer&#34;, &#34;Autumn&#34;]
    values = [
        date_counts.loc[[&#34;Jan&#34;, &#34;Feb&#34;, &#34;Mar&#34;]].sum(),
        date_counts.loc[[&#34;Apr&#34;, &#34;May&#34;, &#34;Jun&#34;]].sum(),
        date_counts.loc[[&#34;Jul&#34;, &#34;Aug&#34;, &#34;Sep&#34;]].sum(),
        date_counts.loc[[&#34;Oct&#34;, &#34;Nov&#34;, &#34;Dec&#34;]].sum(),
    ]
    print(f&#34;{seasons[0]}: {values[0]}&#34;)
    print(f&#34;{seasons[1]}: {values[1]}&#34;)
    print(f&#34;{seasons[2]}: {values[2]}&#34;)
    print(f&#34;{seasons[3]}: {values[3]}&#34;)

    return seasons, values</code></pre>
</details>
</dd>
<dt id="Brownsville.BrownsvilleAPI.Brownsville.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename: str = None, overwrite_file: bool = False) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Saves the current state of the dataset as a <code>.csv</code> file at the path specified during
class instantiation.</p>
<h2 id="parameters">Parameters:</h2>
<p>filename: <code>str</code>
Name for the file being stored.
force_save: <code>bool</code>
Flag indicating whether the file should be overwritten or not.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filename: str = None, overwrite_file: bool = False) -&gt; None:
    &#34;&#34;&#34;
    Saves the current state of the dataset as a `.csv` file at the path specified during
    class instantiation.

    Parameters:
    -----------
    filename: `str`
        Name for the file being stored.
    force_save: `bool`
        Flag indicating whether the file should be overwritten or not.
    &#34;&#34;&#34;
    if not filename:
        filename = self.path + &#34;brownsville.csv&#34;

    if os.path.exists(filename):
        if not overwrite_file:
            inp = input(&#34;File already exists. Type y/Y to overwrite: &#34;)
            if inp.lower() != &#34;y&#34;:
                return

    self.data.to_csv(filename)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="Brownsville.BrownsvilleAPI.InvalidColumnNameError"><code class="flex name class">
<span>class <span class="ident">InvalidColumnNameError</span></span>
<span>(</span><span>msg: str = 'Invalid column name passed')</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InvalidColumnNameError(Exception):
    def __init__(self, msg: str = &#34;Invalid column name passed&#34;) -&gt; None:
        super().__init__(msg)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="Brownsville" href="index.html">Brownsville</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="Brownsville.BrownsvilleAPI.Brownsville" href="#Brownsville.BrownsvilleAPI.Brownsville">Brownsville</a></code></h4>
<ul class="">
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.buildings" href="#Brownsville.BrownsvilleAPI.Brownsville.buildings">buildings</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.complaint_number" href="#Brownsville.BrownsvilleAPI.Brownsville.complaint_number">complaint_number</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.complaints" href="#Brownsville.BrownsvilleAPI.Brownsville.complaints">complaints</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.display_map" href="#Brownsville.BrownsvilleAPI.Brownsville.display_map">display_map</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.get_common_complaint_categories" href="#Brownsville.BrownsvilleAPI.Brownsville.get_common_complaint_categories">get_common_complaint_categories</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.get_date_range" href="#Brownsville.BrownsvilleAPI.Brownsville.get_date_range">get_date_range</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.get_feature_occurrences_by_building" href="#Brownsville.BrownsvilleAPI.Brownsville.get_feature_occurrences_by_building">get_feature_occurrences_by_building</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.get_feature_occurrences_by_key" href="#Brownsville.BrownsvilleAPI.Brownsville.get_feature_occurrences_by_key">get_feature_occurrences_by_key</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.records_by_date" href="#Brownsville.BrownsvilleAPI.Brownsville.records_by_date">records_by_date</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.records_by_season" href="#Brownsville.BrownsvilleAPI.Brownsville.records_by_season">records_by_season</a></code></li>
<li><code><a title="Brownsville.BrownsvilleAPI.Brownsville.save" href="#Brownsville.BrownsvilleAPI.Brownsville.save">save</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="Brownsville.BrownsvilleAPI.InvalidColumnNameError" href="#Brownsville.BrownsvilleAPI.InvalidColumnNameError">InvalidColumnNameError</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>